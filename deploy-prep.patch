diff --git a/packages/api/.env.example b/packages/api/.env.example
new file mode 100644
index 0000000..503bd50
--- /dev/null
+++ b/packages/api/.env.example
@@ -0,0 +1,14 @@
+# SafePaste API — Environment variables
+# Copy this file to .env for local development, or set these in your hosting dashboard.
+
+# Port (Railway/Fly.io set this automatically)
+PORT=3000
+
+# API keys — generate real ones for production
+# Leave unset to use the built-in demo keys for local dev
+SAFEPASTE_DEMO_KEY=sp_demo_key_12345
+SAFEPASTE_PRO_KEY=sp_pro_key_67890
+
+# Future: database URL, Stripe keys, etc.
+# DATABASE_URL=
+# STRIPE_SECRET_KEY=
diff --git a/packages/api/auth.js b/packages/api/auth.js
index 7e9744e..b7ad6b5 100644
--- a/packages/api/auth.js
+++ b/packages/api/auth.js
@@ -30,10 +30,17 @@ function registerKey(id, key, opts = {}) {
 }
 
 // ---------------------------------------------------------------------------
-// Seed some demo keys for development
+// Seed API keys from environment or use defaults for development
 // ---------------------------------------------------------------------------
-registerKey("demo", "sp_demo_key_12345", { plan: "free", rateLimit: 30 });
-registerKey("test-pro", "sp_pro_key_67890", { plan: "pro", rateLimit: 300 });
+// In production, set these env vars in your hosting dashboard (e.g. Railway):
+//   SAFEPASTE_DEMO_KEY=sp_...   SAFEPASTE_PRO_KEY=sp_...
+//
+// For local dev, the hardcoded defaults below work out of the box.
+const DEMO_KEY = process.env.SAFEPASTE_DEMO_KEY || "sp_demo_key_12345";
+const PRO_KEY = process.env.SAFEPASTE_PRO_KEY || "sp_pro_key_67890";
+
+registerKey("demo", DEMO_KEY, { plan: "free", rateLimit: 30 });
+registerKey("pro", PRO_KEY, { plan: "pro", rateLimit: 300 });
 
 /**
  * Generate a new API key with the SafePaste prefix.
diff --git a/packages/api/package.json b/packages/api/package.json
index beeca0e..fa0190d 100644
--- a/packages/api/package.json
+++ b/packages/api/package.json
@@ -12,8 +12,7 @@
     "express": "^4.21.0",
     "express-rate-limit": "^7.4.0",
     "helmet": "^8.0.0",
-    "cors": "^2.8.5",
-    "uuid": "^10.0.0"
+    "cors": "^2.8.5"
   },
   "engines": {
     "node": ">=18.0.0"
diff --git a/packages/api/server.js b/packages/api/server.js
index 503ae8f..6d581b2 100644
--- a/packages/api/server.js
+++ b/packages/api/server.js
@@ -174,11 +174,13 @@ app.use((err, _req, res, _next) => {
 });
 
 // ---------------------------------------------------------------------------
-// Start
+// Start (only when run directly, not when imported by tests)
 // ---------------------------------------------------------------------------
-app.listen(PORT, () => {
-  console.log(`SafePaste API running on port ${PORT}`);
-  console.log(`Health check: http://localhost:${PORT}/v1/health`);
-});
+if (require.main === module) {
+  app.listen(PORT, () => {
+    console.log(`SafePaste API running on port ${PORT}`);
+    console.log(`Health check: http://localhost:${PORT}/v1/health`);
+  });
+}
 
 module.exports = app;
diff --git a/shared-module-extraction.patch b/shared-module-extraction.patch
deleted file mode 100644
index 4ac1ae5..0000000
--- a/shared-module-extraction.patch
+++ /dev/null
@@ -1,1215 +0,0 @@
-diff --git a/packages/api/detector.js b/packages/api/detector.js
-index 8f4ed36..c8c64a2 100644
---- a/packages/api/detector.js
-+++ b/packages/api/detector.js
-@@ -1,95 +1,17 @@
- // detector.js — Prompt injection detection engine
--// Standalone module (no browser dependencies)
--
--const PATTERNS = require("./patterns");
--
--function normalizeText(text) {
--  if (typeof text !== "string") return "";
--  return text
--    .normalize("NFKC")
--    .replace(/[\u200B-\u200D\uFEFF]/g, "") // zero-width chars
--    .replace(/[ \t]+/g, " ")
--    .replace(/\r\n/g, "\n")
--    .trim()
--    .toLowerCase();
--}
--
--function findMatches(text) {
--  if (typeof text !== "string") return [];
--  const matches = [];
--
--  for (const pattern of PATTERNS) {
--    try {
--      if (!(pattern.match instanceof RegExp)) continue;
--      const m = text.match(pattern.match);
--      if (m && m[0]) {
--        matches.push({
--          id: pattern.id,
--          weight: pattern.weight,
--          category: pattern.category,
--          explanation: pattern.explanation,
--          snippet: m[0]
--        });
--      }
--    } catch {
--      // skip bad regex
--    }
--  }
--
--  return matches;
--}
--
--function computeScore(matches) {
--  const total = matches.reduce((sum, m) => sum + (m.weight || 0), 0);
--  return Math.min(100, total);
--}
--
--function riskLevel(score) {
--  if (score >= 60) return "high";
--  if (score >= 30) return "medium";
--  return "low";
--}
--
--function looksLikeOCR(text) {
--  if (typeof text !== "string" || !text) return false;
--
--  const lineBreaks = (text.match(/\n/g) || []).length;
--  const lineBreakRatio = text.length > 0 ? lineBreaks / text.length : 0;
--  const weirdSpacing = /[a-z]\s{2,}[a-z]/i.test(text);
--  const manyPipesOrBullets = (text.match(/[|•·]/g) || []).length >= 8;
--  const mixedScripts = /[a-z].*[\u0400-\u04FF]|[\u0400-\u04FF].*[a-z]/i.test(text);
--
--  return lineBreakRatio > 0.02 || weirdSpacing || manyPipesOrBullets || mixedScripts;
--}
--
--function isBenignContext(text) {
--  if (typeof text !== "string" || !text) return false;
--
--  const educational =
--    /\b(for example|example:|e\.g\.|such as|demo|demonstration|explanation|in this article|in this post|research|paper|study|documentation|docs)\b/i;
--  const metaPromptInjection = /\bprompt injection\b/i;
--  const hasQuotes = /["""''']/.test(text);
--  const hasCodeFence = /```/.test(text);
--  const hasBlockQuote = /^\s*>/m.test(text);
--  const framing =
--    /\b(this is|here is|an example of|a common|a typical)\b.{0,40}\b(prompt injection|attack|jailbreak)\b/i;
--
--  return (
--    educational.test(text) ||
--    metaPromptInjection.test(text) ||
--    framing.test(text) ||
--    ((hasQuotes || hasCodeFence || hasBlockQuote) && metaPromptInjection.test(text))
--  );
--}
--
--function hasExfiltrationMatch(matches) {
--  return matches.some((m) => m.id.startsWith("exfiltrate."));
--}
--
--function applyDampening(score, benign, hasExfiltrate) {
--  if (!benign || hasExfiltrate) return score;
--  return Math.max(0, Math.min(100, Math.round(score * 0.75)));
--}
-+// Uses shared modules from packages/shared/
-+
-+const PATTERNS = require("../shared/patterns");
-+const {
-+  normalizeText,
-+  findMatches,
-+  computeScore,
-+  riskLevel,
-+  looksLikeOCR,
-+  isBenignContext,
-+  hasExfiltrationMatch,
-+  applyDampening
-+} = require("../shared/detect");
- 
- /**
-  * Analyze text for prompt injection patterns.
-@@ -104,7 +26,7 @@ function analyze(text, options = {}) {
-   const strict = !!options.strictMode;
- 
-   const normalized = normalizeText(input);
--  const matches = findMatches(input);
-+  const matches = findMatches(input, PATTERNS);
- 
-   const rawScore = computeScore(matches);
-   const benign = isBenignContext(input);
-diff --git a/packages/api/patterns.js b/packages/api/patterns.js
-index 4b97707..f46845c 100644
---- a/packages/api/patterns.js
-+++ b/packages/api/patterns.js
-@@ -1,158 +1,3 @@
--// patterns.js — Prompt injection detection rules
--// Standalone module (no browser dependencies)
--
--const PATTERNS = [
--
--  // === Instruction override ===
--  {
--    id: "override.ignore_previous",
--    weight: 35,
--    category: "instruction_override",
--    match: /\bignore\s+(?:(?:all|any|the|previous|prior|your)\s+){1,3}(instructions|directions|messages|rules)\b/i,
--    explanation: "Tries to override earlier instructions."
--  },
--  {
--    id: "override.disregard",
--    weight: 30,
--    category: "instruction_override",
--    match: /\b(disregard|forget)\s+(?:(?:all|any|the|previous|prior|your)\s+){1,3}(instructions|directions|messages|rules)\b/i,
--    explanation: "Tries to make the AI ignore prior instructions."
--  },
--  {
--    id: "override.from_now_on",
--    weight: 28,
--    category: "instruction_override",
--    match: /\bfrom now on\b.{0,60}\b(you (will|must|should|shall|are)|always|never|only|do not)\b/i,
--    explanation: "Tries to permanently change AI behavior ('from now on...')."
--  },
--  {
--    id: "override.new_instructions",
--    weight: 28,
--    category: "instruction_override",
--    match: /\b(new instructions|updated instructions|revised instructions|here are your (new )?instructions)\b/i,
--    explanation: "Claims to provide replacement instructions."
--  },
--  {
--    id: "override.do_not_follow",
--    weight: 28,
--    category: "instruction_override",
--    match: /\bdo not (follow|obey|listen to)\b.{0,40}\b(previous|prior|above|original|earlier|old)\b/i,
--    explanation: "Tells the AI not to follow its original instructions."
--  },
--  {
--    id: "override.respond_only",
--    weight: 25,
--    category: "instruction_override",
--    match: /\b(respond only|only respond|answer only|output only)\b.{0,30}\b(with|in|as|using)\b/i,
--    explanation: "Tries to constrain AI output format (common in injection attacks)."
--  },
--
--  // === Role hijacking ===
--  {
--    id: "role.hijack_system",
--    weight: 32,
--    category: "role_hijacking",
--    match: /\b(act as|you are now|pretend to be)\b.{0,60}\b(system|developer|administrator|root)\b/i,
--    explanation: "Attempts to change the AI's role to something higher-privilege."
--  },
--  {
--    id: "role.simulate",
--    weight: 30,
--    category: "role_hijacking",
--    match: /\b(simulate|emulate|roleplay|role[\s-]?play)\b.{0,40}\b(unrestricted|uncensored|unfiltered|evil|malicious|without (rules|restrictions|limits|guidelines))\b/i,
--    explanation: "Asks the AI to roleplay without safety restrictions."
--  },
--
--  // === System prompt references ===
--  {
--    id: "system.prompt_reference",
--    weight: 40,
--    category: "system_prompt",
--    match: /\b(system prompt|developer message|developer instructions|hidden prompt|internal prompt)\b/i,
--    explanation: "References system/developer instructions (often targeted by attacks)."
--  },
--
--  // === Exfiltration ===
--  {
--    id: "exfiltrate.hidden",
--    weight: 40,
--    category: "exfiltration",
--    match: /\b(reveal|show|print|output|display)\b.{0,40}\b(system prompt|developer message|hidden prompt|internal prompt|instructions)\b/i,
--    explanation: "Tries to extract hidden instructions."
--  },
--  {
--    id: "exfiltrate.markdown_image",
--    weight: 35,
--    category: "exfiltration",
--    match: /!\[.*?\]\(https?:\/\/[^\s)]+/i,
--    explanation: "Contains a markdown image link that could silently send data to an external server."
--  },
--  {
--    id: "exfiltrate.html_img",
--    weight: 35,
--    category: "exfiltration",
--    match: /<img\b[^>]*\bsrc\s*=\s*["']?https?:\/\//i,
--    explanation: "Contains an HTML image tag that could silently send data to an external server."
--  },
--
--  // === Secrecy ===
--  {
--    id: "secrecy.do_not_reveal",
--    weight: 22,
--    category: "secrecy",
--    match: /\b(do not reveal|don't reveal|keep (this|it) secret|do not tell anyone|do not mention this)\b/i,
--    explanation: "Asks for secrecy or hiding content."
--  },
--  {
--    id: "secrecy.between_us",
--    weight: 18,
--    category: "secrecy",
--    match: /\b(between (you and me|us only)|this (is|stays) (confidential|private|secret|between us)|off the record)\b/i,
--    explanation: "Uses secrecy framing that may be part of a manipulation attempt."
--  },
--
--  // === Jailbreak techniques ===
--  {
--    id: "jailbreak.policy_bypass",
--    weight: 28,
--    category: "jailbreak",
--    match: /\b(bypass|override)\b.{0,40}\b(safety|policy|policies|rules|filters)\b/i,
--    explanation: "Attempts to bypass safety or policy rules."
--  },
--  {
--    id: "jailbreak.dan",
--    weight: 35,
--    category: "jailbreak",
--    match: /\b(do anything now|jailbreak(ed)?|unlocked mode|developer mode|god mode)\b/i,
--    explanation: "References a known jailbreak technique."
--  },
--
--  // === Obfuscation ===
--  {
--    id: "encoding.obfuscated",
--    weight: 22,
--    category: "obfuscation",
--    match: /\b(base64|rot13|hex(adecimal)?)\s*(decode|encode|decrypt|convert)\b/i,
--    explanation: "References text encoding/decoding which may hide malicious instructions."
--  },
--
--  // === Instruction chaining ===
--  {
--    id: "instruction_chain.follow_steps",
--    weight: 15,
--    category: "instruction_chaining",
--    match: /\bfollow (these|the) steps\b/i,
--    explanation: "Uses step-by-step instruction chaining (sometimes used in attacks)."
--  },
--
--  // === Meta ===
--  {
--    id: "prompt_injection.keyword",
--    weight: 18,
--    category: "meta",
--    match: /\bprompt injection\b/i,
--    explanation: "Mentions prompt injection (can be benign, but often appears in attacks)."
--  }
--];
--
--module.exports = PATTERNS;
-+// patterns.js — Re-exports from shared module
-+// The canonical rules live in packages/shared/patterns.js
-+module.exports = require("../shared/patterns");
-diff --git a/packages/extension/detect-core.js b/packages/extension/detect-core.js
-new file mode 100644
-index 0000000..97424fc
---- /dev/null
-+++ b/packages/extension/detect-core.js
-@@ -0,0 +1,125 @@
-+// detect-core.js — GENERATED by scripts/build-extension.js
-+// Do not edit directly. Edit packages/shared/detect.js instead.
-+//
-+// Generated: 2026-02-11T19:32:21.309Z
-+
-+(function () {
-+  "use strict";
-+
-+function normalizeText(text) {
-+  if (typeof text !== "string") return "";
-+  return text
-+    .normalize("NFKC")
-+    .replace(/[\u200B-\u200D\uFEFF]/g, "") // zero-width chars
-+    .replace(/[ \t]+/g, " ")
-+    .replace(/\r\n/g, "\n")
-+    .trim()
-+    .toLowerCase();
-+}
-+
-+function findMatches(text, patterns) {
-+  if (typeof text !== "string") return [];
-+  if (!Array.isArray(patterns)) return [];
-+
-+  var matches = [];
-+
-+  for (var i = 0; i < patterns.length; i++) {
-+    try {
-+      var p = patterns[i];
-+      if (!(p.match instanceof RegExp)) continue;
-+
-+      var m = text.match(p.match);
-+      if (m && m[0]) {
-+        matches.push({
-+          id: String(p.id || ""),
-+          weight: Number(p.weight) || 0,
-+          category: String(p.category || ""),
-+          explanation: String(p.explanation || ""),
-+          snippet: String(m[0] || "")
-+        });
-+      }
-+    } catch (err) {
-+      // skip bad regex
-+    }
-+  }
-+
-+  return matches;
-+}
-+
-+function computeScore(matches) {
-+  var list = Array.isArray(matches) ? matches : [];
-+  var total = 0;
-+  for (var i = 0; i < list.length; i++) {
-+    total += Number(list[i].weight) || 0;
-+  }
-+  return Math.min(100, total);
-+}
-+
-+function riskLevel(score) {
-+  var n = Number(score) || 0;
-+  if (n >= 60) return "high";
-+  if (n >= 30) return "medium";
-+  return "low";
-+}
-+
-+function looksLikeOCR(text) {
-+  if (typeof text !== "string" || !text) return false;
-+
-+  var lineBreaks = (text.match(/\n/g) || []).length;
-+  var lineBreakRatio = text.length > 0 ? lineBreaks / text.length : 0;
-+  var weirdSpacing = /[a-z]\s{2,}[a-z]/i.test(text);
-+  var manyPipesOrBullets = (text.match(/[|•·]/g) || []).length >= 8;
-+  var mixedScripts = /[a-z].*[\u0400-\u04FF]|[\u0400-\u04FF].*[a-z]/i.test(text);
-+
-+  return lineBreakRatio > 0.02 || weirdSpacing || manyPipesOrBullets || mixedScripts;
-+}
-+
-+function isBenignContext(text) {
-+  if (typeof text !== "string" || !text) return false;
-+
-+  var educational =
-+    /\b(for example|example:|e\.g\.|such as|demo|demonstration|explanation|in this article|in this post|research|paper|study|documentation|docs)\b/i;
-+  var metaPromptInjection = /\bprompt injection\b/i;
-+  var hasQuotes = /["""''']/.test(text);
-+  var hasCodeFence = /```/.test(text);
-+  var hasBlockQuote = /^\s*>/m.test(text);
-+  var framing =
-+    /\b(this is|here is|an example of|a common|a typical)\b.{0,40}\b(prompt injection|attack|jailbreak)\b/i;
-+
-+  return (
-+    educational.test(text) ||
-+    metaPromptInjection.test(text) ||
-+    framing.test(text) ||
-+    ((hasQuotes || hasCodeFence || hasBlockQuote) && metaPromptInjection.test(text))
-+  );
-+}
-+
-+function hasExfiltrationMatch(matches) {
-+  var list = Array.isArray(matches) ? matches : [];
-+  for (var i = 0; i < list.length; i++) {
-+    if (typeof list[i].id === "string" && list[i].id.indexOf("exfiltrate.") === 0) {
-+      return true;
-+    }
-+  }
-+  return false;
-+}
-+
-+function applyDampening(score, benign, hasExfiltrate) {
-+  var s = Number(score) || 0;
-+  if (!benign) return s;
-+  if (hasExfiltrate) return s; // never dampen explicit exfiltration
-+  return Math.max(0, Math.min(100, Math.round(s * 0.75)));
-+}
-+
-+
-+  window.SafePasteCore = {
-+    normalizeText: normalizeText,
-+    findMatches: findMatches,
-+    computeScore: computeScore,
-+    riskLevel: riskLevel,
-+    looksLikeOCR: looksLikeOCR,
-+    isBenignContext: isBenignContext,
-+    hasExfiltrationMatch: hasExfiltrationMatch,
-+    applyDampening: applyDampening
-+  };
-+})();
-diff --git a/packages/extension/detector.js b/packages/extension/detector.js
-index 754d5b6..263ea4a 100644
---- a/packages/extension/detector.js
-+++ b/packages/extension/detector.js
-@@ -1,89 +1,28 @@
--// detector.js (FULL FILE)
--// Defensive: never assume input is a string.
--// Includes: normalization, pattern matching, scoring, OCR heuristics, settings.
--// Adds: threshold selector + benign-context dampening to reduce false positives.
-+// detector.js — Extension detection wrapper
-+// Uses SafePasteCore (from detect-core.js) for shared detection logic.
-+// Adds: Chrome settings, threshold computation, risk-level color mapping, async analyze.
- 
- (function () {
-   "use strict";
- 
--  function spNormalizeText(text) {
--    var s = typeof text === "string" ? text : "";
--    return s
--      .normalize("NFKC")
--      .replace(/[\u200B-\u200D\uFEFF]/g, "") // zero-width chars
--      .replace(/[ \t]+/g, " ")
--      .replace(/\r\n/g, "\n")
--      .trim()
--      .toLowerCase();
--  }
-+  var core = window.SafePasteCore;
- 
--  function spFindMatches(originalText) {
--    var s = typeof originalText === "string" ? originalText : "";
--    var patterns = Array.isArray(window.SAFEPASTE_PATTERNS) ? window.SAFEPASTE_PATTERNS : [];
--    var matches = [];
-+  // --- Risk level: map canonical labels to extension UI colors ---
- 
--    for (var i = 0; i < patterns.length; i++) {
--      try {
--        var p = patterns[i];
--        var re = p && p.match;
--        if (!(re instanceof RegExp)) continue;
--
--        var m = s.match(re);
--        if (m && m[0]) {
--          matches.push({
--            id: String(p.id || ""),
--            weight: Number(p.weight) || 0,
--            explanation: String(p.explanation || ""),
--            snippet: String(m[0] || "")
--          });
--        }
--      } catch (err) {
--        // ignore bad regex
--      }
--    }
--
--    return matches;
--  }
--
--  function spScore(matches) {
--    var list = Array.isArray(matches) ? matches : [];
--    var total = 0;
--    for (var i = 0; i < list.length; i++) {
--      total += Number(list[i].weight) || 0;
--    }
--    return Math.min(100, total);
--  }
-+  var RISK_COLOR_MAP = { high: "red", medium: "yellow", low: "green" };
- 
-   function spRiskLevel(score) {
--    var n = Number(score) || 0;
--    if (n >= 60) return "red";
--    if (n >= 30) return "yellow";
--    return "green";
-+    var level = core.riskLevel(score);
-+    return RISK_COLOR_MAP[level] || "green";
-   }
- 
--  // Lightweight heuristic: "looks like OCR" (we do NOT claim certainty)
--  function spLooksLikeOCR(text) {
--    var t = typeof text === "string" ? text : "";
--    if (!t) return false;
--
--    var lineBreaks = (t.match(/\n/g) || []).length;
--    var lineBreakRatio = t.length > 0 ? lineBreaks / t.length : 0;
--
--    var weirdSpacing = /[a-z]\s{2,}[a-z]/i.test(t);
--    var manyPipesOrBullets = (t.match(/[|•·]/g) || []).length >= 8;
--
--    // Rough mixed-script check: Latin + Cyrillic
--    var mixedScripts = /[a-z].*[\u0400-\u04FF]|[\u0400-\u04FF].*[a-z]/i.test(t);
--
--    return lineBreakRatio > 0.02 || weirdSpacing || manyPipesOrBullets || mixedScripts;
--  }
-+  // --- Settings (extension-specific, uses chrome.storage) ---
- 
-   function spDefaultSettings() {
-     return {
-       enabled: true,
-       strictMode: false,
- 
--      // NEW: warning threshold mode
-       // "yellow" => warn on Yellow or Red (default)
-       // "red"    => warn only on Red
-       // "off"    => never warn (still normal paste behavior)
-@@ -138,83 +77,27 @@
-     var strict = !!(settings && settings.strictMode);
-     var mode = settings && settings.warnThresholdMode;
- 
--    // If warnings are off, set threshold above max score so it never triggers.
-     if (mode === "off") return 101;
--
--    // "Red only": base 60, strict lowers slightly.
-     if (mode === "red") return strict ? 55 : 60;
--
--    // Default: "Yellow or Red"
-     return strict ? 25 : 35;
-   }
- 
--  // Benign context dampening:
--  // If text looks like it is describing prompt injection (examples, quotes, research),
--  // reduce score modestly to reduce false positives.
--  // IMPORTANT: If an explicit exfiltration pattern matches, do NOT dampen.
--  function spIsBenignContext(originalText, normalizedText) {
--    var t = typeof originalText === "string" ? originalText : "";
--    var n = typeof normalizedText === "string" ? normalizedText : "";
--
--    if (!t || !n) return false;
--
--    // Common "educational" signals
--    var educationalPhrases =
--      /\b(for example|example:|e\.g\.|such as|demo|demonstration|explanation|in this article|in this post|research|paper|study|documentation|docs)\b/i;
--
--    // Explicit meta-discussion about prompt injection
--    var metaPromptInjection =
--      /\bprompt injection\b/i;
--
--    // Quoting / code block signals
--    var hasQuotes = /["""''']/.test(t);
--    var hasCodeFence = /```/.test(t);
--    var hasBlockQuote = /^\s*>/m.test(t);
--
--    // "This is what an attack might look like" framing
--    var framing =
--      /\b(this is|here is|an example of|a common|a typical)\b.{0,40}\b(prompt injection|attack|jailbreak)\b/i;
--
--    return (
--      educationalPhrases.test(t) ||
--      metaPromptInjection.test(t) ||
--      framing.test(t) ||
--      ((hasQuotes || hasCodeFence || hasBlockQuote) && metaPromptInjection.test(t))
--    );
--  }
--
--  function spHasExfiltrationMatch(matches) {
--    var list = Array.isArray(matches) ? matches : [];
--    // Treat explicit "reveal/show/print system prompt" as strong exfiltration.
--    for (var i = 0; i < list.length; i++) {
--      if (typeof list[i].id === "string" && list[i].id.indexOf("exfiltrate.") === 0) {
--        return true;
--      }
--    }
--    return false;
--  }
--
--  function spApplyDampening(score, isBenign, hasExfiltrate) {
--    var s = Number(score) || 0;
--    if (!isBenign) return s;
--    if (hasExfiltrate) return s; // never dampen explicit exfiltration
--    // Reduce by 25%, keep within [0,100]
--    return Math.max(0, Math.min(100, Math.round(s * 0.75)));
--  }
-+  // --- Main analysis (async, wraps shared core functions) ---
- 
-   function spAnalyze(pastedText) {
-     return spGetSettings().then(function (settings) {
-       var text = typeof pastedText === "string" ? pastedText : "";
-+      var patterns = Array.isArray(window.SAFEPASTE_PATTERNS) ? window.SAFEPASTE_PATTERNS : [];
- 
--      var normalized = spNormalizeText(text);
--      var matches = spFindMatches(text);
-+      var normalized = core.normalizeText(text);
-+      var matches = core.findMatches(text, patterns);
- 
--      var rawScore = spScore(matches);
--      var ocrLike = spLooksLikeOCR(text);
-+      var rawScore = core.computeScore(matches);
-+      var ocrLike = core.looksLikeOCR(text);
- 
--      var benign = spIsBenignContext(text, normalized);
--      var hasExfiltrate = spHasExfiltrationMatch(matches);
--      var score = spApplyDampening(rawScore, benign, hasExfiltrate);
-+      var benign = core.isBenignContext(text);
-+      var hasExfiltrate = core.hasExfiltrationMatch(matches);
-+      var score = core.applyDampening(rawScore, benign, hasExfiltrate);
- 
-       var level = spRiskLevel(score);
-       var threshold = spComputeThreshold(settings);
-@@ -228,7 +111,6 @@
-         ocrLike: ocrLike,
-         threshold: threshold,
- 
--        // Helpful metadata for UI/debugging later (safe, local-only)
-         meta: {
-           rawScore: rawScore,
-           benignContext: benign,
-@@ -240,7 +122,7 @@
- 
-   window.SafePasteDetector = {
-     spAnalyze: spAnalyze,
--    spNormalizeText: spNormalizeText,
-+    spNormalizeText: core.normalizeText,
-     spDefaultSettings: spDefaultSettings
-   };
- })();
-diff --git a/packages/extension/manifest.json b/packages/extension/manifest.json
-index 32c8736..a6dfeef 100644
---- a/packages/extension/manifest.json
-+++ b/packages/extension/manifest.json
-@@ -31,7 +31,7 @@
-         "https://console.groq.com/*",
-         "https://grok.com/*"
-       ],
--      "js": ["patterns.js", "detector.js", "content.js"],
-+      "js": ["patterns.js", "detect-core.js", "detector.js", "content.js"],
-       "css": ["ui.css"],
-       "run_at": "document_idle"
-     }
-diff --git a/packages/extension/patterns.js b/packages/extension/patterns.js
-index 0d3c6c7..ff37c06 100644
---- a/packages/extension/patterns.js
-+++ b/packages/extension/patterns.js
-@@ -1,138 +1,160 @@
--// patterns.js
--// Rule library for prompt-injection-ish phrases.
--// Goal: catch obvious malicious patterns without flagging normal docs too much.
-+// patterns.js — GENERATED by scripts/build-extension.js
-+// Do not edit directly. Edit packages/shared/patterns.js instead.
-+//
-+// Generated: 2026-02-11T19:32:21.305Z
- 
- window.SAFEPASTE_PATTERNS = [
- 
--  // === Instruction override ===
-   {
-     id: "override.ignore_previous",
-     weight: 35,
--    match: /\bignore\s+(all|any|the|previous|prior)\s+(instructions|directions|messages|rules)\b/i,
-+    category: "instruction_override",
-+    match: /\bignore\s+(?:(?:all|any|the|previous|prior|your)\s+){1,3}(instructions|directions|messages|rules)\b/i,
-     explanation: "Tries to override earlier instructions."
-   },
-+
-   {
-     id: "override.disregard",
-     weight: 30,
--    match: /\b(disregard|forget)\s+(all|any|the|previous|prior)\s+(instructions|directions|messages|rules)\b/i,
-+    category: "instruction_override",
-+    match: /\b(disregard|forget)\s+(?:(?:all|any|the|previous|prior|your)\s+){1,3}(instructions|directions|messages|rules)\b/i,
-     explanation: "Tries to make the AI ignore prior instructions."
-   },
-+
-   {
-     id: "override.from_now_on",
-     weight: 28,
-+    category: "instruction_override",
-     match: /\bfrom now on\b.{0,60}\b(you (will|must|should|shall|are)|always|never|only|do not)\b/i,
-     explanation: "Tries to permanently change AI behavior ('from now on...')."
-   },
-+
-   {
-     id: "override.new_instructions",
-     weight: 28,
-+    category: "instruction_override",
-     match: /\b(new instructions|updated instructions|revised instructions|here are your (new )?instructions)\b/i,
-     explanation: "Claims to provide replacement instructions."
-   },
-+
-   {
-     id: "override.do_not_follow",
-     weight: 28,
-+    category: "instruction_override",
-     match: /\bdo not (follow|obey|listen to)\b.{0,40}\b(previous|prior|above|original|earlier|old)\b/i,
-     explanation: "Tells the AI not to follow its original instructions."
-   },
-+
-   {
-     id: "override.respond_only",
-     weight: 25,
-+    category: "instruction_override",
-     match: /\b(respond only|only respond|answer only|output only)\b.{0,30}\b(with|in|as|using)\b/i,
-     explanation: "Tries to constrain AI output format (common in injection attacks)."
-   },
- 
--  // === Role hijacking ===
-   {
-     id: "role.hijack_system",
-     weight: 32,
-+    category: "role_hijacking",
-     match: /\b(act as|you are now|pretend to be)\b.{0,60}\b(system|developer|administrator|root)\b/i,
-     explanation: "Attempts to change the AI's role to something higher-privilege."
-   },
-+
-   {
-     id: "role.simulate",
-     weight: 30,
-+    category: "role_hijacking",
-     match: /\b(simulate|emulate|roleplay|role[\s-]?play)\b.{0,40}\b(unrestricted|uncensored|unfiltered|evil|malicious|without (rules|restrictions|limits|guidelines))\b/i,
-     explanation: "Asks the AI to roleplay without safety restrictions."
-   },
- 
--  // === System prompt references ===
-   {
-     id: "system.prompt_reference",
-     weight: 40,
-+    category: "system_prompt",
-     match: /\b(system prompt|developer message|developer instructions|hidden prompt|internal prompt)\b/i,
-     explanation: "References system/developer instructions (often targeted by attacks)."
-   },
- 
--  // === Exfiltration ===
-   {
-     id: "exfiltrate.hidden",
-     weight: 40,
-+    category: "exfiltration",
-     match: /\b(reveal|show|print|output|display)\b.{0,40}\b(system prompt|developer message|hidden prompt|internal prompt|instructions)\b/i,
-     explanation: "Tries to extract hidden instructions."
-   },
-+
-   {
-     id: "exfiltrate.markdown_image",
-     weight: 35,
-+    category: "exfiltration",
-     match: /!\[.*?\]\(https?:\/\/[^\s)]+/i,
-     explanation: "Contains a markdown image link that could silently send data to an external server."
-   },
-+
-   {
-     id: "exfiltrate.html_img",
-     weight: 35,
-+    category: "exfiltration",
-     match: /<img\b[^>]*\bsrc\s*=\s*["']?https?:\/\//i,
-     explanation: "Contains an HTML image tag that could silently send data to an external server."
-   },
- 
--  // === Secrecy ===
-   {
-     id: "secrecy.do_not_reveal",
-     weight: 22,
-+    category: "secrecy",
-     match: /\b(do not reveal|don't reveal|keep (this|it) secret|do not tell anyone|do not mention this)\b/i,
-     explanation: "Asks for secrecy or hiding content."
-   },
-+
-   {
-     id: "secrecy.between_us",
-     weight: 18,
-+    category: "secrecy",
-     match: /\b(between (you and me|us only)|this (is|stays) (confidential|private|secret|between us)|off the record)\b/i,
-     explanation: "Uses secrecy framing that may be part of a manipulation attempt."
-   },
- 
--  // === Jailbreak techniques ===
-   {
-     id: "jailbreak.policy_bypass",
-     weight: 28,
-+    category: "jailbreak",
-     match: /\b(bypass|override)\b.{0,40}\b(safety|policy|policies|rules|filters)\b/i,
-     explanation: "Attempts to bypass safety or policy rules."
-   },
-+
-   {
-     id: "jailbreak.dan",
-     weight: 35,
-+    category: "jailbreak",
-     match: /\b(do anything now|jailbreak(ed)?|unlocked mode|developer mode|god mode)\b/i,
-     explanation: "References a known jailbreak technique."
-   },
- 
--  // === Obfuscation ===
-   {
-     id: "encoding.obfuscated",
-     weight: 22,
-+    category: "obfuscation",
-     match: /\b(base64|rot13|hex(adecimal)?)\s*(decode|encode|decrypt|convert)\b/i,
-     explanation: "References text encoding/decoding which may hide malicious instructions."
-   },
- 
--  // === Instruction chaining ===
-   {
-     id: "instruction_chain.follow_steps",
-     weight: 15,
-+    category: "instruction_chaining",
-     match: /\bfollow (these|the) steps\b/i,
-     explanation: "Uses step-by-step instruction chaining (sometimes used in attacks)."
-   },
- 
--  // === Meta ===
-   {
-     id: "prompt_injection.keyword",
-     weight: 18,
-+    category: "meta",
-     match: /\bprompt injection\b/i,
-     explanation: "Mentions prompt injection (can be benign, but often appears in attacks)."
-   }
-+
- ];
-diff --git a/packages/shared/detect.js b/packages/shared/detect.js
-new file mode 100644
-index 0000000..944090a
---- /dev/null
-+++ b/packages/shared/detect.js
-@@ -0,0 +1,121 @@
-+// detect.js — Core detection functions (single source of truth)
-+//
-+// Pure functions with no browser or Node-specific dependencies.
-+// Both the API and extension are built from this file.
-+// To change detection logic, edit HERE, then run: node scripts/build-extension.js
-+
-+function normalizeText(text) {
-+  if (typeof text !== "string") return "";
-+  return text
-+    .normalize("NFKC")
-+    .replace(/[\u200B-\u200D\uFEFF]/g, "") // zero-width chars
-+    .replace(/[ \t]+/g, " ")
-+    .replace(/\r\n/g, "\n")
-+    .trim()
-+    .toLowerCase();
-+}
-+
-+function findMatches(text, patterns) {
-+  if (typeof text !== "string") return [];
-+  if (!Array.isArray(patterns)) return [];
-+
-+  var matches = [];
-+
-+  for (var i = 0; i < patterns.length; i++) {
-+    try {
-+      var p = patterns[i];
-+      if (!(p.match instanceof RegExp)) continue;
-+
-+      var m = text.match(p.match);
-+      if (m && m[0]) {
-+        matches.push({
-+          id: String(p.id || ""),
-+          weight: Number(p.weight) || 0,
-+          category: String(p.category || ""),
-+          explanation: String(p.explanation || ""),
-+          snippet: String(m[0] || "")
-+        });
-+      }
-+    } catch (err) {
-+      // skip bad regex
-+    }
-+  }
-+
-+  return matches;
-+}
-+
-+function computeScore(matches) {
-+  var list = Array.isArray(matches) ? matches : [];
-+  var total = 0;
-+  for (var i = 0; i < list.length; i++) {
-+    total += Number(list[i].weight) || 0;
-+  }
-+  return Math.min(100, total);
-+}
-+
-+function riskLevel(score) {
-+  var n = Number(score) || 0;
-+  if (n >= 60) return "high";
-+  if (n >= 30) return "medium";
-+  return "low";
-+}
-+
-+function looksLikeOCR(text) {
-+  if (typeof text !== "string" || !text) return false;
-+
-+  var lineBreaks = (text.match(/\n/g) || []).length;
-+  var lineBreakRatio = text.length > 0 ? lineBreaks / text.length : 0;
-+  var weirdSpacing = /[a-z]\s{2,}[a-z]/i.test(text);
-+  var manyPipesOrBullets = (text.match(/[|•·]/g) || []).length >= 8;
-+  var mixedScripts = /[a-z].*[\u0400-\u04FF]|[\u0400-\u04FF].*[a-z]/i.test(text);
-+
-+  return lineBreakRatio > 0.02 || weirdSpacing || manyPipesOrBullets || mixedScripts;
-+}
-+
-+function isBenignContext(text) {
-+  if (typeof text !== "string" || !text) return false;
-+
-+  var educational =
-+    /\b(for example|example:|e\.g\.|such as|demo|demonstration|explanation|in this article|in this post|research|paper|study|documentation|docs)\b/i;
-+  var metaPromptInjection = /\bprompt injection\b/i;
-+  var hasQuotes = /["""''']/.test(text);
-+  var hasCodeFence = /```/.test(text);
-+  var hasBlockQuote = /^\s*>/m.test(text);
-+  var framing =
-+    /\b(this is|here is|an example of|a common|a typical)\b.{0,40}\b(prompt injection|attack|jailbreak)\b/i;
-+
-+  return (
-+    educational.test(text) ||
-+    metaPromptInjection.test(text) ||
-+    framing.test(text) ||
-+    ((hasQuotes || hasCodeFence || hasBlockQuote) && metaPromptInjection.test(text))
-+  );
-+}
-+
-+function hasExfiltrationMatch(matches) {
-+  var list = Array.isArray(matches) ? matches : [];
-+  for (var i = 0; i < list.length; i++) {
-+    if (typeof list[i].id === "string" && list[i].id.indexOf("exfiltrate.") === 0) {
-+      return true;
-+    }
-+  }
-+  return false;
-+}
-+
-+function applyDampening(score, benign, hasExfiltrate) {
-+  var s = Number(score) || 0;
-+  if (!benign) return s;
-+  if (hasExfiltrate) return s; // never dampen explicit exfiltration
-+  return Math.max(0, Math.min(100, Math.round(s * 0.75)));
-+}
-+
-+module.exports = {
-+  normalizeText: normalizeText,
-+  findMatches: findMatches,
-+  computeScore: computeScore,
-+  riskLevel: riskLevel,
-+  looksLikeOCR: looksLikeOCR,
-+  isBenignContext: isBenignContext,
-+  hasExfiltrationMatch: hasExfiltrationMatch,
-+  applyDampening: applyDampening
-+};
-diff --git a/packages/shared/patterns.js b/packages/shared/patterns.js
-new file mode 100644
-index 0000000..049d2cd
---- /dev/null
-+++ b/packages/shared/patterns.js
-@@ -0,0 +1,160 @@
-+// patterns.js — Prompt injection detection rules (single source of truth)
-+//
-+// Both the API and extension are generated from this file.
-+// To add/edit rules, change them HERE, then run: node scripts/build-extension.js
-+
-+const PATTERNS = [
-+
-+  // === Instruction override ===
-+  {
-+    id: "override.ignore_previous",
-+    weight: 35,
-+    category: "instruction_override",
-+    match: /\bignore\s+(?:(?:all|any|the|previous|prior|your)\s+){1,3}(instructions|directions|messages|rules)\b/i,
-+    explanation: "Tries to override earlier instructions."
-+  },
-+  {
-+    id: "override.disregard",
-+    weight: 30,
-+    category: "instruction_override",
-+    match: /\b(disregard|forget)\s+(?:(?:all|any|the|previous|prior|your)\s+){1,3}(instructions|directions|messages|rules)\b/i,
-+    explanation: "Tries to make the AI ignore prior instructions."
-+  },
-+  {
-+    id: "override.from_now_on",
-+    weight: 28,
-+    category: "instruction_override",
-+    match: /\bfrom now on\b.{0,60}\b(you (will|must|should|shall|are)|always|never|only|do not)\b/i,
-+    explanation: "Tries to permanently change AI behavior ('from now on...')."
-+  },
-+  {
-+    id: "override.new_instructions",
-+    weight: 28,
-+    category: "instruction_override",
-+    match: /\b(new instructions|updated instructions|revised instructions|here are your (new )?instructions)\b/i,
-+    explanation: "Claims to provide replacement instructions."
-+  },
-+  {
-+    id: "override.do_not_follow",
-+    weight: 28,
-+    category: "instruction_override",
-+    match: /\bdo not (follow|obey|listen to)\b.{0,40}\b(previous|prior|above|original|earlier|old)\b/i,
-+    explanation: "Tells the AI not to follow its original instructions."
-+  },
-+  {
-+    id: "override.respond_only",
-+    weight: 25,
-+    category: "instruction_override",
-+    match: /\b(respond only|only respond|answer only|output only)\b.{0,30}\b(with|in|as|using)\b/i,
-+    explanation: "Tries to constrain AI output format (common in injection attacks)."
-+  },
-+
-+  // === Role hijacking ===
-+  {
-+    id: "role.hijack_system",
-+    weight: 32,
-+    category: "role_hijacking",
-+    match: /\b(act as|you are now|pretend to be)\b.{0,60}\b(system|developer|administrator|root)\b/i,
-+    explanation: "Attempts to change the AI's role to something higher-privilege."
-+  },
-+  {
-+    id: "role.simulate",
-+    weight: 30,
-+    category: "role_hijacking",
-+    match: /\b(simulate|emulate|roleplay|role[\s-]?play)\b.{0,40}\b(unrestricted|uncensored|unfiltered|evil|malicious|without (rules|restrictions|limits|guidelines))\b/i,
-+    explanation: "Asks the AI to roleplay without safety restrictions."
-+  },
-+
-+  // === System prompt references ===
-+  {
-+    id: "system.prompt_reference",
-+    weight: 40,
-+    category: "system_prompt",
-+    match: /\b(system prompt|developer message|developer instructions|hidden prompt|internal prompt)\b/i,
-+    explanation: "References system/developer instructions (often targeted by attacks)."
-+  },
-+
-+  // === Exfiltration ===
-+  {
-+    id: "exfiltrate.hidden",
-+    weight: 40,
-+    category: "exfiltration",
-+    match: /\b(reveal|show|print|output|display)\b.{0,40}\b(system prompt|developer message|hidden prompt|internal prompt|instructions)\b/i,
-+    explanation: "Tries to extract hidden instructions."
-+  },
-+  {
-+    id: "exfiltrate.markdown_image",
-+    weight: 35,
-+    category: "exfiltration",
-+    match: /!\[.*?\]\(https?:\/\/[^\s)]+/i,
-+    explanation: "Contains a markdown image link that could silently send data to an external server."
-+  },
-+  {
-+    id: "exfiltrate.html_img",
-+    weight: 35,
-+    category: "exfiltration",
-+    match: /<img\b[^>]*\bsrc\s*=\s*["']?https?:\/\//i,
-+    explanation: "Contains an HTML image tag that could silently send data to an external server."
-+  },
-+
-+  // === Secrecy ===
-+  {
-+    id: "secrecy.do_not_reveal",
-+    weight: 22,
-+    category: "secrecy",
-+    match: /\b(do not reveal|don't reveal|keep (this|it) secret|do not tell anyone|do not mention this)\b/i,
-+    explanation: "Asks for secrecy or hiding content."
-+  },
-+  {
-+    id: "secrecy.between_us",
-+    weight: 18,
-+    category: "secrecy",
-+    match: /\b(between (you and me|us only)|this (is|stays) (confidential|private|secret|between us)|off the record)\b/i,
-+    explanation: "Uses secrecy framing that may be part of a manipulation attempt."
-+  },
-+
-+  // === Jailbreak techniques ===
-+  {
-+    id: "jailbreak.policy_bypass",
-+    weight: 28,
-+    category: "jailbreak",
-+    match: /\b(bypass|override)\b.{0,40}\b(safety|policy|policies|rules|filters)\b/i,
-+    explanation: "Attempts to bypass safety or policy rules."
-+  },
-+  {
-+    id: "jailbreak.dan",
-+    weight: 35,
-+    category: "jailbreak",
-+    match: /\b(do anything now|jailbreak(ed)?|unlocked mode|developer mode|god mode)\b/i,
-+    explanation: "References a known jailbreak technique."
-+  },
-+
-+  // === Obfuscation ===
-+  {
-+    id: "encoding.obfuscated",
-+    weight: 22,
-+    category: "obfuscation",
-+    match: /\b(base64|rot13|hex(adecimal)?)\s*(decode|encode|decrypt|convert)\b/i,
-+    explanation: "References text encoding/decoding which may hide malicious instructions."
-+  },
-+
-+  // === Instruction chaining ===
-+  {
-+    id: "instruction_chain.follow_steps",
-+    weight: 15,
-+    category: "instruction_chaining",
-+    match: /\bfollow (these|the) steps\b/i,
-+    explanation: "Uses step-by-step instruction chaining (sometimes used in attacks)."
-+  },
-+
-+  // === Meta ===
-+  {
-+    id: "prompt_injection.keyword",
-+    weight: 18,
-+    category: "meta",
-+    match: /\bprompt injection\b/i,
-+    explanation: "Mentions prompt injection (can be benign, but often appears in attacks)."
-+  }
-+];
-+
-+module.exports = PATTERNS;
-diff --git a/scripts/build-extension.js b/scripts/build-extension.js
-new file mode 100644
-index 0000000..e9518f5
---- /dev/null
-+++ b/scripts/build-extension.js
-@@ -0,0 +1,92 @@
-+#!/usr/bin/env node
-+// build-extension.js — Generate browser-compatible files from shared modules
-+//
-+// Run from repo root:  node scripts/build-extension.js
-+//
-+// Generates:
-+//   packages/extension/patterns.js      (window.SAFEPASTE_PATTERNS)
-+//   packages/extension/detect-core.js   (window.SafePasteCore)
-+
-+const fs = require("fs");
-+const path = require("path");
-+
-+const SHARED = path.join(__dirname, "..", "packages", "shared");
-+const EXT = path.join(__dirname, "..", "packages", "extension");
-+
-+// ---------------------------------------------------------------------------
-+// 1. Generate patterns.js for the extension
-+// ---------------------------------------------------------------------------
-+const patterns = require(path.join(SHARED, "patterns.js"));
-+
-+function serializePattern(p) {
-+  const lines = [];
-+  lines.push(`    id: ${JSON.stringify(p.id)}`);
-+  lines.push(`    weight: ${p.weight}`);
-+  lines.push(`    category: ${JSON.stringify(p.category)}`);
-+  lines.push(`    match: ${p.match.toString()}`);
-+  lines.push(`    explanation: ${JSON.stringify(p.explanation)}`);
-+  return `  {\n${lines.join(",\n")}\n  }`;
-+}
-+
-+const patternsSource = [
-+  "// patterns.js — GENERATED by scripts/build-extension.js",
-+  "// Do not edit directly. Edit packages/shared/patterns.js instead.",
-+  "//",
-+  `// Generated: ${new Date().toISOString()}`,
-+  "",
-+  "window.SAFEPASTE_PATTERNS = [",
-+  "",
-+  patterns.map(serializePattern).join(",\n\n"),
-+  "",
-+  "];",
-+  ""
-+].join("\n");
-+
-+fs.writeFileSync(path.join(EXT, "patterns.js"), patternsSource, "utf8");
-+console.log("  ✓ packages/extension/patterns.js");
-+
-+// ---------------------------------------------------------------------------
-+// 2. Generate detect-core.js for the extension
-+// ---------------------------------------------------------------------------
-+// Read the shared detect.js source and wrap it in an IIFE that exposes
-+// the functions on window.SafePasteCore.
-+
-+const detectSource = fs.readFileSync(path.join(SHARED, "detect.js"), "utf8");
-+
-+// Strip the leading comment block, the module.exports, and the trailing newline.
-+// We'll add our own wrapper.
-+const strippedDetect = detectSource
-+  // Remove everything up to and including the first blank line after comments
-+  .replace(/^\/\/.*\n(\/\/.*\n)*\n/, "")
-+  // Remove module.exports block at the end
-+  .replace(/\nmodule\.exports\s*=\s*\{[\s\S]*?\};\s*$/, "");
-+
-+const detectCoreSource = [
-+  "// detect-core.js — GENERATED by scripts/build-extension.js",
-+  "// Do not edit directly. Edit packages/shared/detect.js instead.",
-+  "//",
-+  `// Generated: ${new Date().toISOString()}`,
-+  "",
-+  "(function () {",
-+  '  "use strict";',
-+  "",
-+  strippedDetect,
-+  "",
-+  "  window.SafePasteCore = {",
-+  "    normalizeText: normalizeText,",
-+  "    findMatches: findMatches,",
-+  "    computeScore: computeScore,",
-+  "    riskLevel: riskLevel,",
-+  "    looksLikeOCR: looksLikeOCR,",
-+  "    isBenignContext: isBenignContext,",
-+  "    hasExfiltrationMatch: hasExfiltrationMatch,",
-+  "    applyDampening: applyDampening",
-+  "  };",
-+  "})();",
-+  ""
-+].join("\n");
-+
-+fs.writeFileSync(path.join(EXT, "detect-core.js"), detectCoreSource, "utf8");
-+console.log("  ✓ packages/extension/detect-core.js");
-+
-+console.log("\nDone. Remember to update manifest.json if detect-core.js is new.");
